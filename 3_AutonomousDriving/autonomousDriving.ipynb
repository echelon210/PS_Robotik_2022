{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Python Script to drive the Jetbot autonomous while reacting to signs on the track\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "# LOAD MODELS\n",
    "# Model for Sign Detection:\n",
    "modelSignDetection = torchvision.models.squeezenet1_1(pretrained=False)\n",
    "modelSignDetection.classifier[1] = torch.nn.Conv2d(512, 7, kernel_size=1)\n",
    "modelSignDetection.num_classes = 7\n",
    "modelSignDetection.load_state_dict(torch.load('signDetection_V2_squeeze_conv.pth'))\n",
    "\n",
    "# Model for Road Following\n",
    "modelRoadFollowing = torchvision.models.squeezenet1_1(pretrained=False)\n",
    "modelRoadFollowing.classifier[1] = torch.nn.Conv2d(512, 1, kernel_size=1)\n",
    "modelRoadFollowing.num_classes = 1\n",
    "modelRoadFollowing.load_state_dict(torch.load('roadFollowing_V3_squeeze_conv.pth'))\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Push models to GPU and apply half() datatype\n",
    "modelSignDetection = modelSignDetection.to(device)\n",
    "modelSignDetection = modelSignDetection.eval().half()\n",
    "modelRoadFollowing = modelRoadFollowing.to(device)\n",
    "modelRoadFollowing = modelRoadFollowing.eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmean = 255.0 * np.array([0.485, 0.456, 0.406])\\nstdev = 255.0 * np.array([0.229, 0.224, 0.225])\\n\\nnormalize = torchvision.transforms.Normalize(mean, stdev)\\n\\ndef preprocessSign(camera_value):\\n    global device, normalize\\n    x = camera_value\\n    x[0:224, int(224*0): int(224*2/4)] =(0,0,0)\\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\\n    x = x.transpose((2, 0, 1))\\n    x = torch.from_numpy(x).float()\\n    x = normalize(x)\\n    x = x.to(device)\\n    x = x[None, ...]\\n    return x\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    \"\"\" \n",
    "    Method to preprocess images for the sign detection and road following models. \n",
    "    In(1): image - The image to preprocess as array\n",
    "    Out(1): preprocessed image\n",
    "    \"\"\"\n",
    "    # Activate the following line to mask the left half of the picture\n",
    "    # -> Sign detection is only neccessary on right side\n",
    "    # -> Is deactivated to combine preprocessing for both models in one method and to safe runtime\n",
    "    # image[0:224, int(224*0): int(224*2/4)] =(0,0,0)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d77f9613ed4784937880accce7fb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='fast', max=1.0, orientation='vertical'), FloatSlider(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229f0194dbe9466a96f6a9db171e066b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c477fa159969443f978de29a84596e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c986f9adcae0440fa4f4daaee5b08560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4199f589b31418ba888f890a90141b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='braking', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584d21a84ae04f31b52322424702d361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "FPS = 10  # NOTE: System runs stable with about 10 FPS\n",
    "display_image = False  # NOTE: Displaying the image will cost a lot of computational ressources. Only display for debugging!\n",
    "\n",
    "# DISPLAY DASHBOARD\n",
    "camera = Camera.instance(width=224, height=224, fps=FPS)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# Sign Detection Sliders\n",
    "fast_slider = widgets.FloatSlider(description='fast', min=0.0, max=1.0, orientation='vertical')\n",
    "left_slider = widgets.FloatSlider(description='left', min=0.0, max=1.0, orientation='vertical')\n",
    "right_slider = widgets.FloatSlider(description='right', min=0.0, max=1.0, orientation='vertical')\n",
    "slow_slider = widgets.FloatSlider(description='slow', min=0.0, max=1.0, orientation='vertical')\n",
    "stop_slider = widgets.FloatSlider(description='stop', min=0.0, max=1.0, orientation='vertical')\n",
    "nothing_slider = widgets.FloatSlider(description='nothing', min=0.0, max=1.0, orientation='vertical')\n",
    "attention_slider = widgets.FloatSlider(description='attention', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "if display_image:\n",
    "    display(widgets.HBox([image, fast_slider, left_slider, right_slider, slow_slider, stop_slider, attention_slider, nothing_slider]))\n",
    "else:\n",
    "    display(widgets.HBox([fast_slider, left_slider, right_slider, slow_slider, stop_slider, attention_slider, nothing_slider]))\n",
    "\n",
    "# Driving Sliders\n",
    "speed_gain_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.0, description='steering gain')\n",
    "steering_dgain_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_slider = widgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, brake_slider, steering_slider)\n",
    "\n",
    "# Init Robot to access ressources\n",
    "from jetbot import Robot\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "### GLOBAL VARIABLES ###\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "# Timer related signs\n",
    "isStop = False\n",
    "stopTimer = 100\n",
    "isAttention = False\n",
    "attentionTimer = 100\n",
    "\n",
    "# Slow and fast\n",
    "isSlow = False\n",
    "driveSlow = False\n",
    "isFast = False\n",
    "\n",
    "# Turning signs\n",
    "isRight = False\n",
    "goRight = False\n",
    "isLeft = False\n",
    "goLeft = False\n",
    "straightTimerRight = 100 \n",
    "straightTimerLeft = 100\n",
    "\n",
    "\n",
    "def update(change):    \n",
    "    \"\"\" \n",
    "    Method that is called for every new incoming image from the camera stream.\n",
    "    Note: EVERY image will access this method because they are stacked as a queue. Therefore it is not possible to apply functionalities that \n",
    "    stop the program flow in this method because the image queue will grow and cause stability issues.\n",
    "    \"\"\"\n",
    "    global fast_slider, left_slider, right_slider, slow_slider, stop_slider, nothing_slider, attention_slider, speed_slider\n",
    "    global robot, angle, angle_last \n",
    "    global isStop, stopTimer, isAttention, attentionTimer, isSlow, driveSlow, isFast, isRight, goRight, isLeft, goLeft, straightTimerRight, straightTimerLeft\n",
    "    image = camera.value\n",
    "    image_preprocessed = preprocess(image)\n",
    "    \n",
    "    # Read speed\n",
    "    target_velocity = speed_gain_slider.value\n",
    "    \n",
    "    ### SIGN DETECTION ###\n",
    "    # Strategy:\n",
    "    # A sign will be detected when its probability coming from sign detection CNN reaches a certain value.\n",
    "    # When a sign is detected the procedure waits till it disappears to ensure that the robot drives nearby\n",
    "    # the sign before reacting to it. After this certain reaction strategies are implemented depending\n",
    "    # on the actual sign.\n",
    "    \n",
    "    signs = modelSignDetection(image_preprocessed).detach().float().cpu()\n",
    "    \n",
    "    # Read out probabilities\n",
    "    signs = F.softmax(signs, dim=1)\n",
    "    prob_fast = float(signs.flatten()[1])\n",
    "    prob_left = float(signs.flatten()[2])\n",
    "    prob_right = float(signs.flatten()[4])\n",
    "    prob_slow = float(signs.flatten()[5])\n",
    "    prob_stop = float(signs.flatten()[6])\n",
    "    prob_nothing = float(signs.flatten()[3])\n",
    "    prob_attention = float(signs.flatten()[0])\n",
    "    \n",
    "    # STOP SIGN HANDLING\n",
    "    # ---> Stop for 2 seconds\n",
    "    if prob_stop >= 0.95:\n",
    "        isStop = True  \n",
    "    \n",
    "    if prob_stop <= 0.1 and isStop == True: \n",
    "        stopTimer = 0\n",
    "        isStop = False\n",
    "    \n",
    "    if stopTimer < (2 * FPS):  # Wait for two seconds\n",
    "        robot.left_motor.value = 0.0\n",
    "        robot.right_motor.value = 0.0\n",
    "        stopTimer += 1\n",
    "        return\n",
    "    \n",
    "    # ATTENTION SIGN HANDLING\n",
    "    # ---> Drive slow for 2 seconds\n",
    "    if prob_attention >= 0.95:\n",
    "        isAttention = True\n",
    "    \n",
    "    if prob_attention <= 0.1 and isAttention == True:\n",
    "        attentionTimer = 0\n",
    "        isAttention = False\n",
    "    \n",
    "    if attentionTimer < (2 * FPS):\n",
    "        target_velocity = 0.09\n",
    "        attentionTimer += 1\n",
    "        \n",
    "    # 30 SIGN HANDLING\n",
    "    # ---> Drive slow until fast sign appears\n",
    "    if prob_slow >= 0.95:\n",
    "        isSlow = True\n",
    "        \n",
    "    if prob_slow <= 0.1 and isSlow == True:\n",
    "        driveSlow = True\n",
    "        isSlow = False\n",
    "    \n",
    "    if driveSlow:\n",
    "        target_velocity = 0.09\n",
    "        \n",
    "    # FAST SIGN HANDLING\n",
    "    # ---> Release slow sign state\n",
    "    if prob_fast >= 0.7:\n",
    "        isFast = True\n",
    "    \n",
    "    if prob_fast <= 0.1 and isFast == True:\n",
    "        driveSlow = False\n",
    "        isFast = False\n",
    "        target_velocity = speed_gain_slider.value\n",
    "        \n",
    "    # RIGHT SIGN HANDLING\n",
    "    # ---> Turn right\n",
    "    if prob_right >= 0.95:\n",
    "        isRight = True\n",
    "        \n",
    "    if prob_right <= 0.1 and isRight == True:\n",
    "        goRight = True\n",
    "        isRight = False\n",
    "        straightTimerRight = 0\n",
    "        \n",
    "    if goRight and straightTimerRight < (2 * FPS):\n",
    "        # Run straight into crossroad\n",
    "        target_velocity = 0.12\n",
    "        target_velocity = 0.12\n",
    "        straightTimerRight += 1\n",
    "    elif goRight and straightTimerRight < (3 * FPS):\n",
    "        # Turn Right\n",
    "        robot.left_motor.value = 0.14\n",
    "        robot.right_motor.value = - 0.14\n",
    "        straightTimerRight += 1\n",
    "        return\n",
    "    else:\n",
    "        goRight = False\n",
    "        \n",
    "    # Left SIGN HANDLING\n",
    "    # ---> Turn left\n",
    "    if prob_left >= 0.95:\n",
    "        isLeft = True\n",
    "        \n",
    "    if prob_left <= 0.1 and isLeft == True:\n",
    "        goLeft = True\n",
    "        isLeft = False\n",
    "        straightTimerLeft = 0\n",
    "        \n",
    "    if goLeft and straightTimerLeft < (2 * FPS):\n",
    "        # Run straight into crossroad\n",
    "        target_velocity = 0.12\n",
    "        target_velocity = 0.12\n",
    "        straightTimerLeft += 1\n",
    "    elif goLeft and straightTimerLeft < (3 * FPS):\n",
    "        # Turn Left\n",
    "        robot.left_motor.value = - 0.14\n",
    "        robot.right_motor.value = 0.14\n",
    "        straightTimerLeft += 1\n",
    "        return\n",
    "    else:\n",
    "        goLeft = False\n",
    "    \n",
    "    # Visualization\n",
    "    fast_slider.value = prob_fast\n",
    "    left_slider.value = prob_left\n",
    "    right_slider.value = prob_right\n",
    "    slow_slider.value = prob_slow\n",
    "    stop_slider.value = prob_stop\n",
    "    nothing_slider.value = prob_nothing\n",
    "    attention_slider.value = prob_attention\n",
    "    \n",
    "    ### LANE DETECTION ###\n",
    "    angle = modelRoadFollowing(image_preprocessed).detach().float().cpu().numpy().flatten()\n",
    "    angle = angle - 90\n",
    "    angle = np.deg2rad(angle)\n",
    "    \n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid  # Visualize steering \n",
    "    \n",
    "    robot.left_motor.value = max(min(target_velocity + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(target_velocity - steering_slider.value, 1.0), 0.0)\n",
    "        \n",
    "update({'new': camera.value}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LAUNCH CONTROL ###\n",
    "camera.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLANK CELL TO AVIOD KILLING ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KILL ###\n",
    "import time\n",
    "camera.unobserve(update, names='value')\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
