{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BENCHMARKING OF THE DIFFERENT PROCEDURES TO CALCULATE A STEERING ANGLE FROM INPUT PICTURES\n",
    "# Notebook to compare the execution speed of the ResNet, SqueezeNet and OpenCV procedure for 200 testpictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# LOAD RESNET\n",
    "resnet = torchvision.models.resnet18(pretrained=False)\n",
    "resnet.fc = torch.nn.Linear(512, 1)\n",
    "resnet.load_state_dict(torch.load('roadFollowing_V2_resnet_conv.pth'))\n",
    "resnet = resnet.to(device)\n",
    "resnet = resnet.eval().half()\n",
    "\n",
    "# LOAD SQUEEZENET\n",
    "squeezenet = torchvision.models.squeezenet1_1(pretrained=False)\n",
    "squeezenet.classifier[1] = torch.nn.Conv2d(512, 1, kernel_size=1)\n",
    "squeezenet.num_classes = 1\n",
    "squeezenet.load_state_dict(torch.load('roadFollowing_V3_squeeze_conv.pth'))\n",
    "squeezenet = squeezenet.to(device)\n",
    "squeezenet = squeezenet.eval().half()\n",
    "\n",
    "# DEFINE OPEN CV PROCEDURE\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def maskImage(image):\n",
    "    \"\"\" Method to define a region of interest with masking an image. \n",
    "        In(1): image - The image that should be masked \n",
    "        In(2): heightPercent - The percent of the height that should be masked\n",
    "        Out(1): returns a image where half of the image is masked with a black surface\n",
    "    \"\"\"\n",
    "    height, width = image.shape\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # A polygon defining the region that should be masked as np.array\n",
    "    polygon = np.array([[\n",
    "        (0, height * 0.0),  # Up left\n",
    "        (width, height * 0.0),  # \n",
    "        (width, height),\n",
    "        (0, height),\n",
    "    ]], np.int32)\n",
    "\n",
    "    cv2.fillPoly(mask, polygon, 255)\n",
    "    return cv2.bitwise_and(image, mask)\n",
    "\n",
    "def findCenterline(image):\n",
    "    slope = 0.0\n",
    "\n",
    "    # Apply gaussian image blurring\n",
    "    gaussKernelSize = (3, 3)\n",
    "    blurred_img = cv2.GaussianBlur(image, gaussKernelSize, 0)\n",
    "    \n",
    "    # Convert to HSV image representation\n",
    "    hsv_img = cv2.cvtColor(blurred_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Filter out yellow of the center line\n",
    "    low_yellow = np.array([5, 40, 100])\n",
    "    up_yellow = np.array([50, 255, 255])\n",
    "    col_img = cv2.inRange(hsv_img, low_yellow, up_yellow)\n",
    "    \n",
    "    # Filter out region of interest\n",
    "    region_img = maskImage(col_img)\n",
    "    \n",
    "    # Apply canny edge detection\n",
    "    canny_img = cv2.Canny(region_img, 100, 150)\n",
    "    \n",
    "    lines = cv2.HoughLinesP(canny_img, rho=1, theta=np.pi/180, threshold=30, lines=np.array([]), minLineLength=5, maxLineGap=50)\n",
    "    if np.any(lines) == None:\n",
    "        pass\n",
    "    else:\n",
    "        # Center line detection\n",
    "        lines_x = []\n",
    "        lines_y = []\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                lines_x.extend([x1, x2])\n",
    "                lines_y.extend([y1, y2])\n",
    "\n",
    "        min_y = int(image.shape[0] * 0.0)\n",
    "        max_y = image.shape[0]  # <-- The bottom of the image\n",
    "        \n",
    "        poly = np.poly1d(np.polyfit(lines_y, lines_x, deg=1))\n",
    "        center_x_start = int(image.shape[1] * 0.5)  # start in the middle of the picture\n",
    "        center_x_end = int(poly(min_y))\n",
    "\n",
    "        if (center_x_end - center_x_start) == 0:\n",
    "            slope = 0\n",
    "        else:\n",
    "            slope = round(np.rad2deg(np.arctan2((max_y - min_y),\n",
    "                          (center_x_start - center_x_end))) - 90, 3)\n",
    "    return slope\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking result for OpenCV:\n",
      "---> Mean time to process a picture:  0.004404 s      =>    FPS: 227.07684692488556\n",
      "---> Standard deviation in the time:  0.002817\n",
      "---> Maximum occured processing time: 0.011779 s\n",
      "\n",
      "Benchmarking result for SQUEEZENET:\n",
      "---> Mean time to process a picture:  0.018596 s      =>    FPS: 53.77436915210864\n",
      "---> Standard deviation in the time:  0.002366\n",
      "---> Maximum occured processing time: 0.032016 s\n",
      "\n",
      "Benchmarking result for RESNET:\n",
      "---> Mean time to process a picture:  0.040098 s      =>    FPS: 24.93858998087455\n",
      "---> Standard deviation in the time:  0.001371\n",
      "---> Maximum occured processing time: 0.047792 s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "pictures = os.listdir('benchmarkPictures')\n",
    "\n",
    "def executeSqueezenet(picture):\n",
    "    start = time.time()\n",
    "    angle = squeezenet(preprocess(picture)).detach().float().cpu().numpy().flatten()\n",
    "    angle = np.deg2rad(angle - 90)\n",
    "    return time.time() - start\n",
    "\n",
    "def executeResnet(picture):\n",
    "    start = time.time()\n",
    "    angle = resnet(preprocess(picture)).detach().float().cpu().numpy().flatten()\n",
    "    angle = np.deg2rad(angle)\n",
    "    return time.time() - start\n",
    "\n",
    "def executeOpenCV(picture):\n",
    "    start = time.time()\n",
    "    angle = findCenterline(picture)\n",
    "    angle = np.deg2rad(angle)\n",
    "    return time.time() - start\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "times = []\n",
    "for paths in pictures:\n",
    "    image = PIL.Image.open('benchmarkPictures/' + paths)\n",
    "    pic = np.asarray(image)\n",
    "    times.append(executeOpenCV(pic))\n",
    "\n",
    "print(\"\\nBenchmarking result for OpenCV:\")\n",
    "print(\"---> Mean time to process a picture:  \" + str(round(np.mean(times), 6)) + \" s      =>    FPS: \" + str(1 / np.mean(times)))\n",
    "print(\"---> Standard deviation in the time:  \" + str(round(np.std(times), 6)))\n",
    "print(\"---> Maximum occured processing time: \" + str(round(np.max(times), 6))  + \" s\")\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "times = []\n",
    "for paths in pictures:\n",
    "    image = PIL.Image.open('benchmarkPictures/'+paths)\n",
    "    pic = np.asarray(image)\n",
    "    times.append(executeSqueezenet(pic))\n",
    "    \n",
    "print(\"\\nBenchmarking result for SQUEEZENET:\")\n",
    "print(\"---> Mean time to process a picture:  \" + str(round(np.mean(times), 6)) + \" s      =>    FPS: \" + str(1 / np.mean(times)))\n",
    "print(\"---> Standard deviation in the time:  \" + str(round(np.std(times), 6)))\n",
    "print(\"---> Maximum occured processing time: \" + str(round(np.max(times), 6))  + \" s\")\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "### Do Benchmarking:\n",
    "times = []\n",
    "for paths in pictures:\n",
    "    image = PIL.Image.open('benchmarkPictures/'+paths)\n",
    "    pic = np.asarray(image)\n",
    "    times.append(executeResnet(pic))\n",
    "    \n",
    "print(\"\\nBenchmarking result for RESNET:\")\n",
    "print(\"---> Mean time to process a picture:  \" + str(round(np.mean(times), 6)) + \" s      =>    FPS: \" + str(1 / np.mean(times)))\n",
    "print(\"---> Standard deviation in the time:  \" + str(round(np.std(times), 6)))\n",
    "print(\"---> Maximum occured processing time: \" + str(round(np.max(times), 6))  + \" s\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
